{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    # brew install wget (Run in command line)\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython<3.0.0\n",
      "  Downloading Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: wheel in ./tfod/lib/python3.11/site-packages (0.42.0)\n",
      "Downloading Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.5/989.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "Successfully installed cython-0.29.37\n",
      "Collecting pyyaml==5.4.1\n",
      "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.4.1-cp311-cp311-macosx_13_0_arm64.whl size=45660 sha256=4e4ad5ff282d89ff71b683970369ef04dd5fa67e1525c77cad7e2a6974de576e\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/2f/2f/af/a062a8f866dc44812a825da11175d50d7f255900f3b38c79b5\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "Successfully installed pyyaml-5.4.1\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[33mWarning:\u001b[0m protobuf 25.1 is already installed and up-to-date.\n",
      "To reinstall 25.1, run:\n",
      "  brew reinstall protobuf\n",
      "\u001b[33mWarning:\u001b[0m Already linked: /opt/homebrew/Cellar/protobuf/25.1\n",
      "To relink, run:\n",
      "  brew unlink protobuf && brew link protobuf\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: Cython in ./tfod/lib/python3.11/site-packages (from tf-models-official) (0.29.37)\n",
      "Collecting Pillow (from tf-models-official)\n",
      "  Using cached Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting gin-config (from tf-models-official)\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official)\n",
      "  Using cached google_api_python_client-2.111.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting immutabledict (from tf-models-official)\n",
      "  Using cached immutabledict-4.1.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official)\n",
      "  Using cached kaggle-1.5.16.tar.gz (83 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib (from tf-models-official)\n",
      "  Using cached matplotlib-3.8.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.26.2)\n",
      "Collecting oauth2client (from tf-models-official)\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official)\n",
      "  Using cached opencv_python_headless-4.8.1.78-cp37-abi3-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pandas>=0.22.0 (from tf-models-official)\n",
      "  Using cached pandas-2.1.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (5.9.7)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pycocotools (from tf-models-official)\n",
      "  Using cached pycocotools-2.0.7-cp311-cp311-macosx_10_9_universal2.whl.metadata (1.1 kB)\n",
      "Collecting pyyaml>=6.0.0 (from tf-models-official)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting sacrebleu (from tf-models-official)\n",
      "  Using cached sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy>=0.19.1 (from tf-models-official)\n",
      "  Using cached scipy-1.11.4-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\n",
      "Collecting sentencepiece (from tf-models-official)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Collecting seqeval (from tf-models-official)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in ./tfod/lib/python3.11/site-packages (from tf-models-official) (1.16.0)\n",
      "Collecting tensorflow-datasets (from tf-models-official)\n",
      "  Using cached tensorflow_datasets-4.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting tensorflow-hub>=0.6.0 (from tf-models-official)\n",
      "  Using cached tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
      "  Using cached tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.14.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.14.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.13.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached tf_models_official-2.13.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official)\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tf-models-official\n",
      "  Using cached tf_models_official-2.13.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in ./tfod/lib/python3.11/site-packages (from tf-models-official) (5.4.1)\n",
      "  Downloading tf_models_official-2.12.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tensorflow-addons (from tf-models-official)\n",
      "  Downloading tensorflow_addons-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.12.0-py2.py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.11.6-py2.py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.11.5-py2.py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.11.4-py2.py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading tf_models_official-2.11.2-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Downloading tf_models_official-2.11.0-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25h  Downloading tf_models_official-2.10.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hCollecting sacrebleu==2.2.0 (from tf-models-official)\n",
      "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25h  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Downloading tf_models_official-2.9.1-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.9.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.7.2-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.7.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.6.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tf_models_official-2.5.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow>=2.5.0 (from tf-models-official)\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting tf-slim>=1.1.0 (from tf-models-official)\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Collecting httplib2<1.dev0,>=0.15.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0.dev0,>=1.19.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: certifi in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: requests in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.31.0)\n",
      "Collecting tqdm (from kaggle>=1.3.9->tf-models-official)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-slugify (from kaggle>=1.3.9->tf-models-official)\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (2.1.0)\n",
      "Requirement already satisfied: bleach in ./tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official) (6.1.0)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.22.0->tf-models-official)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas>=0.22.0->tf-models-official)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-macos==2.15.0 (from tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Using cached protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in ./tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official) (69.0.3)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Using cached grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-tree~=0.1.1 (from tensorflow-model-optimization>=0.4.1->tf-models-official)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-macosx_11_0_arm64.whl (110 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib->tf-models-official)\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->tf-models-official)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->tf-models-official)\n",
      "  Downloading fonttools-4.47.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (157 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->tf-models-official)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->tf-models-official)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyasn1>=0.1.7 (from oauth2client->tf-models-official)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules>=0.0.5 (from oauth2client->tf-models-official)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa>=3.1.4 (from oauth2client->tf-models-official)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting portalocker (from sacrebleu->tf-models-official)\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting regex (from sacrebleu->tf-models-official)\n",
      "  Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->tf-models-official)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting colorama (from sacrebleu->tf-models-official)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: lxml in ./tfod/lib/python3.11/site-packages (from sacrebleu->tf-models-official) (4.9.4)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval->tf-models-official)\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting click (from tensorflow-datasets->tf-models-official)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Downloading etils-1.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting promise (from tensorflow-datasets->tf-models-official)\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->tf-models-official)\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting toml (from tensorflow-datasets->tf-models-official)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting fsspec (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting importlib_resources (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting zipp (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tfod/lib/python3.11/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tfod/lib/python3.11/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.6)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.21.3->seqeval->tf-models-official)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval->tf-models-official)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: webencodings in ./tfod/lib/python3.11/site-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in ./tfod/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official) (0.42.0)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./tfod/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official) (2.1.3)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_python_client-2.111.0-py2.py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.1.4-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-macosx_12_0_arm64.whl (29.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (208.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.8/208.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.2-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.8.1.78-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.7-cp311-cp311-macosx_10_9_universal2.whl (170 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (243 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading etils-1.6.0-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.9/144.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.47.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.15.0-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.0/122.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio-1.60.0-cp311-cp311-macosx_10_10_universal2.whl (9.7 MB)\n",
      "Downloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, seqeval\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110683 sha256=926ef34cfcdca356e7e4063956f94b6d6c5940db6d3d096b6744c2f93665773c\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/6a/2b/d0/457dd27de499e9423caf738e743c4a3f82886ee6b19f89d5b7\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a25a3aa569c312d69e72b51922a1f82d074c0b6eb0a6a6987d8bd12b38c236cd\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built kaggle seqeval\n",
      "Installing collected packages: text-unidecode, sentencepiece, pytz, py-cpuinfo, libclang, gin-config, flatbuffers, dm-tree, zipp, wrapt, werkzeug, uritemplate, tzdata, typing-extensions, typeguard, tqdm, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, scipy, regex, python-slugify, pyparsing, pyasn1, protobuf, promise, portalocker, Pillow, opt-einsum, opencv-python-headless, oauthlib, ml-dtypes, markdown, kiwisolver, keras, joblib, importlib_resources, h5py, grpcio, google-pasta, gast, fsspec, fonttools, etils, cycler, contourpy, colorama, click, cachetools, astunparse, absl-py, tf-slim, tensorflow-model-optimization, tensorflow-hub, tensorflow-addons, scikit-learn, sacrebleu, rsa, requests-oauthlib, pyasn1-modules, pandas, matplotlib, kaggle, httplib2, googleapis-common-protos, tensorflow-metadata, seqeval, pycocotools, oauth2client, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, tensorboard, google-api-python-client, tensorflow-macos, tensorflow-datasets, tensorflow, tf-models-official\n",
      "Successfully installed Pillow-10.1.0 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.2 click-8.1.7 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 dm-tree-0.1.8 etils-1.6.0 flatbuffers-23.5.26 fonttools-4.47.0 fsspec-2023.12.2 gast-0.5.4 gin-config-0.5.0 google-api-core-2.15.0 google-api-python-client-2.111.0 google-auth-2.25.2 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 googleapis-common-protos-1.62.0 grpcio-1.60.0 h5py-3.10.0 httplib2-0.22.0 importlib_resources-6.1.1 joblib-1.3.2 kaggle-1.5.16 keras-2.15.0 kiwisolver-1.4.5 libclang-16.0.6 markdown-3.5.1 matplotlib-3.8.2 ml-dtypes-0.2.0 oauth2client-4.1.3 oauthlib-3.2.2 opencv-python-headless-4.8.1.78 opt-einsum-3.3.0 pandas-2.1.4 portalocker-2.8.2 promise-2.3 protobuf-3.20.3 py-cpuinfo-9.0.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pycocotools-2.0.7 pyparsing-3.1.1 python-slugify-8.0.1 pytz-2023.3.post1 regex-2023.12.25 requests-oauthlib-1.3.1 rsa-4.9 sacrebleu-2.4.0 scikit-learn-1.3.2 scipy-1.11.4 sentencepiece-0.1.99 seqeval-1.2.2 tabulate-0.9.0 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.4 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-macos-2.15.0 tensorflow-metadata-1.14.0 tensorflow-model-optimization-0.7.5 termcolor-2.4.0 text-unidecode-1.3 tf-models-official-2.5.1 tf-slim-1.1.0 threadpoolctl-3.2.0 toml-0.10.2 tqdm-4.66.1 typeguard-2.13.3 typing-extensions-4.9.0 tzdata-2023.3 uritemplate-4.1.1 werkzeug-3.0.1 wrapt-1.14.1 zipp-3.17.0\n",
      "Requirement already satisfied: wheel in ./tfod/lib/python3.11/site-packages (0.42.0)\n",
      "Requirement already satisfied: setuptools in ./tfod/lib/python3.11/site-packages (69.0.3)\n",
      "Requirement already satisfied: pip in ./tfod/lib/python3.11/site-packages (23.3.2)\n",
      "Processing /Users/quangnguyen/Documents/gsc24-test/TFODCourse/Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3 (from object_detection==0.1)\n",
      "  Using cached avro-python3-1.10.2.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apache-beam (from object_detection==0.1)\n",
      "  Using cached apache-beam-2.52.0.tar.gz (2.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (10.1.0)\n",
      "Requirement already satisfied: lxml in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (4.9.4)\n",
      "Requirement already satisfied: matplotlib in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (3.8.2)\n",
      "Requirement already satisfied: Cython in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (0.29.37)\n",
      "Collecting contextlib2 (from object_detection==0.1)\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: tf-slim in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (2.0.7)\n",
      "Collecting lvis (from object_detection==0.1)\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (1.11.4)\n",
      "Requirement already satisfied: pandas in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (2.1.4)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (2.5.1)\n",
      "Collecting tensorflow_io (from object_detection==0.1)\n",
      "  Using cached tensorflow_io-0.34.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: keras in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from object_detection==0.1) (2.15.0)\n",
      "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
      "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: portalocker in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: regex in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.2)\n",
      "Requirement already satisfied: colorama in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: gin-config in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.111.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.5.16)\n",
      "Requirement already satisfied: oauth2client in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.8.1.78)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.1.99)\n",
      "Requirement already satisfied: seqeval in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-addons in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.23.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.4)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.15.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.7.5)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2023.3)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache-beam->object_detection==0.1)\n",
      "  Downloading orjson-3.9.10-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle~=2.2.1 (from apache-beam->object_detection==0.1)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
      "  Downloading fastavro-1.9.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.60.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.23.0,>=0.8 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
      "Collecting js2py<1,>=0.74 (from apache-beam->object_detection==0.1)\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.20.0)\n",
      "Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object_detection==0.1)\n",
      "  Using cached numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
      "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (23.2)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
      "  Downloading pymongo-4.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (22 kB)\n",
      "Collecting proto-plus<2,>=1.7.1 (from apache-beam->object_detection==0.1)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (3.20.3)\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.9.0)\n",
      "Collecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n",
      "  Downloading zstandard-0.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow<12.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
      "  Downloading pyarrow-11.0.0-cp311-cp311-macosx_11_0_arm64.whl (22.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from lvis->object_detection==0.1) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from lvis->object_detection==0.1) (1.4.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from lvis->object_detection==0.1) (4.8.1.78)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from matplotlib->object_detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from matplotlib->object_detection==0.1) (4.47.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow_io->object_detection==0.1) (0.34.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.25.2)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.1.1)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tzlocal>=1.2 (from js2py<1,>=0.74->apache-beam->object_detection==0.1)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object_detection==0.1)\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.15.2)\n",
      "Requirement already satisfied: certifi in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2023.11.17)\n",
      "Requirement already satisfied: tqdm in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.66.1)\n",
      "Requirement already satisfied: python-slugify in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: bleach in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.1.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.6)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (69.0.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.3.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.3.2)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object_detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: click in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\n",
      "Requirement already satisfied: etils>=0.9.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.6.0)\n",
      "Requirement already satisfied: promise in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.14.0)\n",
      "Requirement already satisfied: toml in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: fsspec in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2023.12.2)\n",
      "Requirement already satisfied: importlib_resources in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.1.1)\n",
      "Requirement already satisfied: zipp in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: webencodings in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (0.42.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/quangnguyen/Documents/gsc24-test/TFODCourse/tfod/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.2)\n",
      "Downloading tensorflow_io-0.34.0-cp311-cp311-macosx_12_0_arm64.whl (34.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.2-cp311-cp311-macosx_10_9_universal2.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Using cached numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "Downloading orjson-3.9.10-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (242 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.0/242.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pymongo-4.6.1-cp311-cp311-macosx_10_9_universal2.whl (534 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m534.3/534.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.22.0-cp311-cp311-macosx_11_0_arm64.whl (703 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.4/703.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: object_detection, apache-beam, avro-python3, crcmod, dill, hdfs, pyjsparser, docopt\n",
      "  Building wheel for object_detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1656805 sha256=2d6debe7d3a78b99f37b547cbe69cb173819e687e19b70a105d741ca1b90bdfd\n",
      "  Stored in directory: /private/var/folders/n4/7j7k85wj3cj51xb2m6wn13b40000gn/T/pip-ephem-wheel-cache-s0_ux1ei/wheels/72/54/7b/d54a82fcb6400127bcec221d8c802d4346b6db68f440495a66\n",
      "  Building wheel for apache-beam (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apache-beam: filename=apache_beam-2.52.0-cp311-cp311-macosx_13_0_arm64.whl size=5133252 sha256=f2a7fc71b2653a51a8c9690dcb5c8d4599daa31c58d5b0a632383d9c5c0a54c6\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/ac/a3/68/ccd31f88bf45ba840fa4685da8c0fed3d02fd572c515c2e1e6\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=5953367f7ae33fd78c06b774ab7af987ba8da55dfb77d045868b8bc018453420\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/31/be/50/1145d9510eb4440893fc0ec676ef9464a05e0f7492a76fbb2c\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-macosx_13_0_arm64.whl size=22359 sha256=37e8146d79783bf97fb169cab6d7995a1f7afb5dc4d3b2337e189c885469f463\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=6916956ed48f752f76111bdaf56f5060fc565b44076843c1f5b9eece3e4ea579\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/01/60/80/1622338bcecce31a5664ef01c203cc5a7b09f59588d9c07376\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=499a8771306398f26f2cede40bbf429ae30dc7e8c498b03abbc25315b4bfa81d\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/b9/1d/dc/eb0833be25464c359903d356c4204721c6a672c26ff164cdc3\n",
      "  Building wheel for pyjsparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=41e7f7f1eddf03542ec2c2ef17fe08095ec9573c5c49f2aae1e6d4d5e58944c9\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/a5/9a/30/1003e89ab4555b81840ca46d361bf184f1e6ad880cae3b62a9\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=82f2f31798d38d199a68170332d2cf7abef805a5bc222c18c2e18ebd29ffdb6d\n",
      "  Stored in directory: /Users/quangnguyen/Library/Caches/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built object_detection apache-beam avro-python3 crcmod dill hdfs pyjsparser docopt\n",
      "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, tzlocal, tensorflow_io, pyparsing, pyarrow-hotfix, proto-plus, orjson, objsize, numpy, fasteners, fastavro, dnspython, dill, contextlib2, cloudpickle, avro-python3, sacrebleu, pymongo, pydot, pyarrow, js2py, hdfs, lvis, apache-beam, object_detection\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.1\n",
      "    Uninstalling pyparsing-3.1.1:\n",
      "      Successfully uninstalled pyparsing-3.1.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "  Attempting uninstall: sacrebleu\n",
      "    Found existing installation: sacrebleu 2.4.0\n",
      "    Uninstalling sacrebleu-2.4.0:\n",
      "      Successfully uninstalled sacrebleu-2.4.0\n",
      "Successfully installed apache-beam-2.52.0 avro-python3-1.10.2 cloudpickle-2.2.1 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.9.2 fasteners-0.19 hdfs-2.7.3 js2py-0.74 lvis-0.5.3 numpy-1.24.4 object_detection-0.1 objsize-0.6.1 orjson-3.9.10 proto-plus-1.23.0 pyarrow-11.0.0 pyarrow-hotfix-0.6 pydot-1.4.2 pyjsparser-2.7.1 pymongo-4.6.1 pyparsing-2.4.7 sacrebleu-2.2.0 tensorflow_io-0.34.0 tzlocal-5.2 zstandard-0.22.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    #!apt-get install protobuf-compiler\n",
    "    \n",
    "    # Work-around to solve the bug with version confliction of PyYaml and Cython \n",
    "    !pip install \"cython<3.0.0\" wheel\n",
    "    !pip install \"pyyaml==5.4.1\" --no-build-isolation\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    # Install protobuf via brew as package installer\n",
    "    !brew install protobuf\n",
    "    !brew link --overwrite protobuf\n",
    "    !pip install tf-models-official\n",
    "    !pip install wheel setuptools pip --upgrade\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'', 'id':1},\n",
    "          {'name':'', 'id':2},\n",
    "          {'name':'', 'id':3},\n",
    "          {'name':'', 'id':4},\n",
    "          {'name':'', 'id':5},\n",
    "          {'name':'', 'id':6},\n",
    "          {'name':'', 'id':7},\n",
    "          {'name':'', 'id':8},\n",
    "          {'name':'', 'id':9}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWpb_BVUpfDD",
    "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQA13-afpfDF",
    "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "o_grs6OGpfDJ"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\\model.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-03 11:54:23.153051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-04-03 11:54:25.644887: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-03 11:54:25.645576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
      "2021-04-03 11:54:25.667969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-04-03 11:54:25.668001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-04-03 11:54:25.671400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
      "2021-04-03 11:54:25.671416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
      "2021-04-03 11:54:25.673240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-04-03 11:54:25.673772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
      "2021-04-03 11:54:25.677306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
      "2021-04-03 11:54:25.678684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
      "2021-04-03 11:54:25.679228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
      "2021-04-03 11:54:25.679291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-03 11:54:25.679494: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-03 11:54:25.680122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-04-03 11:54:25.680135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-04-03 11:54:25.680141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
      "2021-04-03 11:54:25.680148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
      "2021-04-03 11:54:25.680152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-04-03 11:54:25.680158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
      "2021-04-03 11:54:25.680163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
      "2021-04-03 11:54:25.680167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
      "2021-04-03 11:54:25.680171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
      "2021-04-03 11:54:25.680197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-03 11:54:26.114383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-03 11:54:26.114403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-03 11:54:26.114407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-03 11:54:26.114533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
      "2021-04-03 11:54:26.114935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-03 11:54:34.068925: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-04-03 11:54:34.069068: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-04-03 11:54:34.070081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-04-03 11:54:34.070099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-04-03 11:54:34.070106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
      "2021-04-03 11:54:34.070112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
      "2021-04-03 11:54:34.070119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-04-03 11:54:34.070123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
      "2021-04-03 11:54:34.070130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
      "2021-04-03 11:54:34.070134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
      "2021-04-03 11:54:34.070141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
      "2021-04-03 11:54:34.070164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-04-03 11:54:34.070202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-03 11:54:34.070208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-04-03 11:54:34.070211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-04-03 11:54:34.070267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
      "2021-04-03 11:54:34.070284: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-03 11:54:34.396918: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 4000 nodes (3591), 8430 edges (8014), time = 217.05ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 4.085ms.\n",
      "\n",
      "2021-04-03 11:54:37.417793: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  debug_stripper: Graph size after: 3683 nodes (0), 8201 edges (0), time = 79.922ms.\n",
      "  model_pruner: Graph size after: 3232 nodes (-451), 7750 edges (-451), time = 125.865ms.\n",
      "  constant_folding: Graph size after: 1551 nodes (-1681), 5834 edges (-1916), time = 199.089ms.\n",
      "  arithmetic_optimizer: Graph size after: 1551 nodes (0), 5834 edges (0), time = 33.234ms.\n",
      "  dependency_optimizer: Graph size after: 1453 nodes (-98), 1650 edges (-4184), time = 22.074ms.\n",
      "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 9.534ms.\n",
      "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.71ms.\n",
      "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 22.603ms.\n",
      "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 14.027ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 1.378ms.\n",
      "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 7.504ms.\n",
      "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.06ms.\n",
      "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 23.745ms.\n",
      "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 12.714ms.\n",
      "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 8.842ms.\n",
      "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.59ms.\n",
      "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 23.085ms.\n",
      "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 14.073ms.\n",
      "\n",
      "2021-04-03 11:54:45.020557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 1415 nodes (-114), 1308 edges (-114), time = 6.93ms.\n",
      "  constant_folding: Graph size after: 1111 nodes (-304), 1308 edges (0), time = 45.571ms.\n",
      "  arithmetic_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 18.394ms.\n",
      "  dependency_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 9.992ms.\n",
      "  remapper: Graph size after: 1111 nodes (0), 1308 edges (0), time = 5.143ms.\n",
      "  constant_folding: Graph size after: 1111 nodes (0), 1308 edges (0), time = 22.813ms.\n",
      "  arithmetic_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 18.23ms.\n",
      "  dependency_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 9.571ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8_hm-itpfDK"
   },
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 11. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zip and Export Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
